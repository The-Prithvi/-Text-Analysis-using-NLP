Approch I followed to achive the goal:


1. Firstly I imported all the necessary libraries that will be used for the whole analysis process.

2. Made a dataframe from the given Input excel file using pandas

3. Fetched the response of the url by iterating on the dataframe using requests module.

4. fetched the article and its heading by targeting the class of respective html elements.

5. Handledthe url which got error or failed to fetched by making a separte list of them to handle the analysis further.

6. Made text files of the articles for the individual url and putting all those article's text files in a folder using file io and os module respectively.

7. Cleaned the article by removing unnecessary break lines using string functions and re module.

8. Made a list of all the stop, positive and negative words by fetching them from the text files given in the StopWords and MasterDictionary folder respectively using file io and os module.

9. Removing unnessary symbols, whitespaces and formatting the lists to perform analysis which were made in the point 8th.

10. Made tokens of the article using nltk library.

11. Performed Data Cleaning by removing stop words and punctuations by using the lists prepared in 8th point and using string library.

12. Calculatted all the variables for data analysis and making a list of the calculated scores for each articles also adding those list in a parent list (nested list).

13. Made a data frame based on the nested list made in the 12th point and giving columns names from the  given "Output Data Structure.xlsx" file.

14. After making the dataframe in the 13th point, modifying the dataframe by adding row/s in the dataframe for handling the urls which were failed to fetch at the specified index (with the help of the error list which was made in 5th point).

15. Concating the Dataframes made in the 2nd point and 13th point for the final output.

16. Exported the dataframe in the form of excel file.